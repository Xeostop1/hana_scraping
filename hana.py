from bs4 import BeautifulSoup
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.common.by import By
from selenium.webdriver.common.keys import Keys
from webdriver_manager.chrome import ChromeDriverManager
import csv

user_agent = "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/113.0.0.0 Safari/537.36"

options = webdriver.ChromeOptions()
options.add_argument('--headless=new')
options.add_argument("window-size=1920x1080")
options.add_argument(f"user-agent={user_agent}")
browser = webdriver.Chrome(service=Service(
    ChromeDriverManager().install()), options=options)
# í¬ë¡¬ ì—…ë°ì´íŠ¸ë¡œ install í•„ìš” pip install --upgrade webdriver_manager

# ì¿¼ë¦¬ë¶„ì„ ë„ì¿„
# https://wing.hanatour.com/package/major-products?
# cntryCd=JP&
# cityCd=TYO&
# depCityCd=JCN%2CAF9&
# pkgServiceCd=FP&
# flag=ICE&
# rprsProdAirEnn=Y%2CN&
# prodTypeCd=G%2CI&
# strtDepDay=20231001&
# endDepDay=20231031&
# depCityNm=%EC%9D%B8%EC%B2%9C%2F%EA%B9%80%ED%8F%AC

# %2ëŠ” ì½¤ë§ˆ
# https://wing.hanatour.com/package/major-products?
# cntryCd=JP&
# cityCd=OSA&
# depCityCd=JCN%2CAF9&
# pkgServiceCd=FP&
# flag=ICE&
# rprsProdAirEnn=Y%2CN&
# prodTypeCd=G%2CI&
# strtDepDay=20231001&
# endDepDay=20231031&
# depCityNm=%EC%9D%B8%EC%B2%9C%2F%EA%B9%80%ED%8F%AC

# ë³€ê²½ê°€ëŠ¥ ì½”ë“œ
# strtDepDay= ì¶œë°œì¼
# endDepDay= ë„ì°©ì¼
# cntryCd= êµ­ê°€
# cityCd= ë„ì‹œ
# depCityNm= ì¶œë°œì§€ì—­

strtDepDay = "20231001"
endDepDay = "20231031"
cntryCd = "JP"
cityCd = "TYO"

url = f"https://wing.hanatour.com/package/major-products?cntryCd={cntryCd}&"
url += f"cityCd={cityCd}&depCityCd=JCN%2CAF9&pkgServiceCd=FP&flag=ICE&rprsProdAirEnn=Y%2CN&prodTypeCd=G%2CI&"
url += f"strtDepDay={strtDepDay}&endDepDay={endDepDay}&depCityNm=%EC%9D%B8%EC%B2%9C%2F%EA%B9%80%ED%8F%AC"
all_hash_tags = []

browser.get(url)
soup = BeautifulSoup(browser.page_source, "html.parser")
items = soup.select("ul.type > li")
t_item = []
counter = 1

for i in items:
    img_nodes = i.select_one("div.inr.img>img")  # í™•ì¸
    # ë¦¬ìŠ¤íŠ¸ê°€ ë¹„ì–´ìˆì§€ ì•Šê³  ì²« ë²ˆì§¸ ìš”ì†Œì— 'src' ì†ì„±ì´ ìˆëŠ” ê²½ìš°
    if img_nodes and 'src' in img_nodes.attrs:
        img = img_nodes['src']
        print(img)
    else:
        img = "ì´ë¯¸ì§€ ì—†ìŒ"
    cate_node = i.select_one("span.attr")  # none ìˆìŒ
    if cate_node is not None:
        cate = cate_node.get_text().strip()
    else:
        cate = "ì¹´í…Œê³ ë¦¬ ì—†ìŒ"
    title = i.select_one("strong.item_title.eps3").get_text().strip()  # í™•ì¸
    sub_t = i.select_one("p.item_text.stit").get_text().strip()  # í™•ì¸
    text_node = i.select_one("span.icn.cal")
    if text_node is not None:
        trip_term = text_node.contents[0].strip()
        # print(trip_term)

    hash_list = i.select("span.hash_group")
    for j in hash_list:
        hash_tags = j.select("span")
        # ë¦¬ìŠ¤íŠ¸ ì»´í”„ë¦¬í—¨ì…˜: ê¸°ì¡´ ë¦¬ìŠ¤íŠ¸ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìƒˆë¡œìš´ ë¦¬ìŠ¤íŠ¸ë¥¼ ìƒì„±
        group_hash = [tag.get_text().strip() for tag in hash_tags]
        all_hash_tags.append(group_hash)
    price_node = i.select_one("strong.price")
    if price_node is not None:
        price = price_node.contents[0].strip()
        # print(price)
        # ë”•ì…”ë„ˆë¦¬ë¡œ ë¦¬ìŠ¤íŠ¸ ë„£ê¸°
        item_dict = {
            'id': counter,
            'title': title,
            'price_pc': price,
            'link': url,
            'mobile_link': 'ì—†ìŒ',
            'image_link': img,
            'category_name1': cate,
            'Shipping': 0}

        t_item.append(item_dict)
        # print(item_dict)

        counter += 1

print(t_item)
file_name = "hana_jp_tyo.csv"
path = "./data_excel/"
with open(path+file_name, 'w', newline='',  encoding='utf-8-sig') as f:
    writer = csv.DictWriter(f, fieldnames=[
                            'id', 'title', 'price_pc', 'link', 'mobile_link', 'image_link', 'category_name1', 'Shipping'])
    writer.writeheader()  # í—¤ë” ì“°ê¸°
    writer.writerows(t_item)  # ë°ì´í„° ì“°ê¸°
    print("ì—‘ì…€ íŒŒì¼ ì™„ì„±")

print("ì™„ì„± íŒŒì¼ í™•ì¸í•˜ì„¸ìš” ğŸ¥°")
